{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow - Clustering\n",
    "\n",
    "This notebook continues exploring the the data of the GADS23 Kaggle Stack Overflow competition.\n",
    "\n",
    "Your goal was to build a classifier that predicts whether or not a question will be closed given the question as submitted.\n",
    "\n",
    "Let's see if clustering would be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/ruben/Downloads/train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags\n",
    "One obvious candidate for clustering would be the vast amount of tags we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.42 s, sys: 105 ms, total: 5.53 s\n",
      "Wall time: 5.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['tags'] = data.apply(lambda x: \" \".join(set(str(x['Tag%d' % i]) for i in xrange(1, 6))), axis=1)\n",
    "data['tags'] = data['tags'].str.replace('nan', '').str.replace(\"  \", \" \").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 18309 tags.\n"
     ]
    }
   ],
   "source": [
    "tags = set([tag for tags in data.tags.values for tag in tags.split()])\n",
    "print \"We have\", len(tags), \"tags.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a lot. We could maybe cluster these, and then feed the cluster category into the model, rather than an ID for one of the 18K tags.  We could use `CountVectorizer` for this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "# N = 10000  # only use the first N documents for clustering (to speed up computations)\n",
    "# data = data.iloc[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 22.8 ms, total: 1.04 s\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=5000, min_df=10, max_df=.95, binary=True)\n",
    "X = cv.fit_transform(data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering tags by their documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XT = X.T\n",
    "XT = StandardScaler().fit_transform(XT.toarray().astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 35s, sys: 3.03 s, total: 4min 38s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = KMeans(n_clusters=n_clusters)\n",
    "model.fit(XT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " array([   1,    1, 3226,    1,    1,    1,    1,    1,    1,    1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(XT), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that didn't quite work: almost all tags got into one cluster, and the other clusters just got one tag. (Note we have less tags since we only used part of the data.)\n",
    "\n",
    "#### Clustering documents by their tags\n",
    "\n",
    "One other way we could do, is clustering the documents according to their tags, and then use their document cluster to feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.4 s, sys: 97.9 ms, total: 36.5 s\n",
      "Wall time: 36.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=10, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruben/anaconda/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:862: RuntimeWarning: Got data type int64, converted to float to avoid overflows\n",
      "  X = self._check_test_data(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " array([ 4143,  4314,  1807,  6427,  8624, 10950, 12022,  4622,  5960, 81403]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(X), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Let's inspect the most common tags in these clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 12 tags per cluster:\n",
      "Cluster 0: sql server 2008 mysql database 2005 net tsql query linq oracle windows\n",
      "Cluster 1: html css javascript jquery internet explorer html5 css3 div php browser web\n",
      "Cluster 2: visual studio 2010 net 2008 asp windows vb sql 2005 debugging server\n",
      "Cluster 3: jquery javascript ajax php html ui css plugins mobile json html5 forms\n",
      "Cluster 4: android java layout eclipse listview google iphone emulator application mobile sqlite activity\n",
      "Cluster 5: java ee swing spring web eclipse javascript hibernate jsp php xml multithreading\n",
      "Cluster 6: php mysql javascript html php5 arrays wordpress codeigniter database sql apache facebook\n",
      "Cluster 7: python django google ruby engine app php list web regex mysql numpy\n",
      "Cluster 8: net asp mvc jquery javascript ajax web sql vb framework entity server\n",
      "Cluster 9: iphone javascript net ruby objective ios rails windows linux mysql facebook google\n"
     ]
    }
   ],
   "source": [
    "top = 12\n",
    "print \"Top %d tags per cluster:\" % top\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = cv.get_feature_names()\n",
    "for i in range(n_clusters):\n",
    "    print \"Cluster %d:\" % i,\n",
    "    for ind in order_centroids[i, :top]:\n",
    "        print terms[ind],\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are at least a front-end cluster, a database cluster, and a mobile cluster.  Note that, since we clustered documents, not tags, a tag might be associated with several clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD9CAYAAAC7iRw+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4pekjvn/Us8QVnOTHrQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110e78ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['tag_cluster'] = model.predict(X)\n",
    "s = data.groupby('tag_cluster').OpenStatus.mean().sort(inplace=False)\n",
    "f = s.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in closed posts per cluster suggests we could try extracting some value from this.  We leave it as an exercise to verify if adding these clusters to your feature matrix indeed leads to a higher preduction accuracy.\n",
    "\n",
    "#### Jaccard distance\n",
    "\n",
    "The [_Jaccard index_](https://en.wikipedia.org/wiki/Jaccard_index) is a similarity metric between text documents. It measures how many words two documents have in common, as a fraction of the total number of distinct words in both documents.\n",
    "\n",
    "$$\\text{Jaccard index} = \\frac{ |A \\cap B | }{ |A \\cup B| }$$\n",
    "\n",
    "We could make a Jaccard matrix $J$, with pairwise similarities $J_{ij}$ as entries.\n",
    "- `J[i, j]` = Jaccard similarity between doc _i_ and _j_ (between 0 and 1)\n",
    "- `J[i, i]` = 1, obviously, and\n",
    "- `J[i, j]` = `J[i, j]`, i.e., the matrix is symmetric.\n",
    "\n",
    "We could also define the _Jaccard distance_, which has $D_{ii} = 0$ for identical documents, and bigger values as the documents have less words in common.  We define: $D = 1 - J,$ which has values between 0 and 1.\n",
    "\n",
    "We could also use this for comparing our tags: how many documents do two tages have in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 916 ms, sys: 23.3 ms, total: 939 ms\n",
      "Wall time: 926 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=5000,\n",
    "                     min_df=10, max_df=.95, binary=True)  # binary=True is important!\n",
    "X = cv.fit_transform(data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Jaccard matrix and the distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_tags = X.shape[1]  # number of tags\n",
    "I = X.T.dot(X).toarray()  # X-transposed times X gives a tag x tag matrix with the # of docs in common\n",
    "n_docs = np.diag(I)  # number of docs per tag\n",
    "# U = np.array([[n_docs[i] + n_docs[j] - I[i, j] for i in xrange(n_tags)] for j in xrange(n_tags)])  # this is slow\n",
    "N = np.array([n_docs] * n_tags)  # number of docs broadcasted over the entire row\n",
    "U = N + N.T - I  # total distinct docs = n_docs_i + n_docs_j - words in common\n",
    "J = I / U.astype(float)\n",
    "D = 1 - J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a few random tags and see what the closest tags are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w3c               : w3c validation xhtml standards dtd logo compliance validator digital crud\n",
      "recaptcha         : recaptcha captcha googlebot messagebox prevention spam iframe message redirect error\n",
      "jdk7              : jdk7 jdk1 jdk nio jython jre classes closures jruby production\n",
      "carrierwave       : carrierwave rmagick paperclip rackspace asset pipeline gem compare cloud rails\n",
      "analytics         : analytics google tracking mining flurry usage statistics api intelligence analysis\n",
      "getter            : getter setter phpdoc encapsulation notation dot member blank dao nullpointerexception\n",
      "flexbuilder       : flexbuilder flex4 flex flex3 adobe air actionscript builder access source\n",
      "change            : change password itil isotope radio src textfield detect portlet sas\n",
      "axapta            : axapta ax 2009 dynamics 2012 cobol methods career development forms\n",
      "relational        : relational algebra database non foreign nosql relationship schema databases backbone\n"
     ]
    }
   ],
   "source": [
    "top = 10\n",
    "tags = np.array(cv.get_feature_names())\n",
    "for no in np.random.choice(n_tags, top, replace=False):  # pick 10 random tags\n",
    "    print \"%-18s:\" % tags[no], \" \".join(tags[D[no].argsort()[:top]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense. Some tags have more meaning than others, I expect. Note that this is not a partitioning, as we only have a distance between words.\n",
    "\n",
    "We could also apply `KMeans` to this Jaccard matrix, as the entries are indeed distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tags per cluster:\n",
      "Cluster 0: graduate school masters degree college education systems university science old\n",
      "Cluster 1: web cream sandwich ice net asp internet iphone explorer ios\n",
      "Cluster 2: studio visual 2010 server engine 2008 sql opengl xna app\n",
      "Cluster 3: fault segmentation gdb berkeley scanf resque sfml jit nasm slots\n",
      "Cluster 4: password conf httpd protection passwords recovery alias salt storage encryption\n",
      "Cluster 5: unit tests automated testing mocks tdd rhino integration continuous driven\n",
      "Cluster 6: lotus domino asset notes package pipeline 04 10 directory active\n",
      "Cluster 7: style coding ref counting anonymous handling automatic event types exception\n",
      "Cluster 8: garbage collection ruby rails programming lisp node js languages clojure\n",
      "Cluster 9: procedures stored plsql 2005 cursor server sql tsql oracle db2\n"
     ]
    }
   ],
   "source": [
    "model.fit(D)\n",
    "print \"Top %d tags per cluster:\" % top\n",
    "order_centroids = model.cluster_centers_.argsort()\n",
    "for i in range(n_clusters):\n",
    "    print \"Cluster %d:\" % i, \" \".join(tags[order_centroids[i, :top]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks quite promising.\n",
    "\n",
    "Unfortunately, the model has put a lot of tags into the same cluster again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " array([   7, 2878,  104,    2,   11,   35,   43,   52,  101,    2]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(D), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "## Exercise\n",
    "- Add the cluster information to your feature set and train a model on your data. Does the inclusion of these clusters indeed imporve prediction accuracy?  (Don't forget to cross-validate.)\n",
    "- Try different values for `n_clusters` and see if you could find a good value using the _elbow method_.\n",
    "\n",
    "We have looked at clustering tags by documents, clustering documents by tags, and at the Jaccard distance between two tags using the number of documents they have in common.  \n",
    "- Could you think of other ways of clustering tags or documents?  Try to implement these and see how effective they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
