{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra in Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of our operations on data require translating our raw datasets into something we can write code to operate on.  Often we will attempt to translate raw datasets into tables and perform filter or aggregations.  If our table is made up mostly numerical values, we can also view it as a matrix and use many ideas from linear algebra to help analyze the data stored in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _vector_ is an array of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66993459,  0.63246441,  0.38614197,  0.75450976,  0.28195878,\n",
       "        0.66846293,  0.19292232,  0.2021837 ,  0.82736718,  0.63091287])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.random.random(10)\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two vectors of the same dimension can be added and subtracted, or multiplied by a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.33986917,  1.26492882,  0.77228393,  1.50901952,  0.56391756,\n",
       "        1.33692585,  0.38584463,  0.4043674 ,  1.65473437,  1.26182574])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.33986917,  1.26492882,  0.77228393,  1.50901952,  0.56391756,\n",
       "        1.33692585,  0.38584463,  0.4043674 ,  1.65473437,  1.26182574])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix $M$ can be seen as\n",
    "- a $m \\times n$ grid of elements, or\n",
    "- a collection of vectors, where each column represents a $m \\times 1$ vector (or each row is a $1\\times n$ vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43534357,  0.80832371,  0.74769297],\n",
       "       [ 0.25168462,  0.29323653,  0.93740695]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.random.random((2, 3))  # 2x3 matrix\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43534357,  0.80832371,  0.74769297])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[0]  # first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43534357,  0.25168462])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[:,0]  # first column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _Matrices_ are often notated by a capital letter (e.g., _M_), and\n",
    "- _vectors_ by a lower case letter (e.g., _v_). \n",
    "- A _scalar_, in constrast to a vector, is a single value or variable, and is often notated with a Greek character (e.g., $\\alpha$ or $\\lambda$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = np.random.random((2, 5))\n",
    "v = np.random.random(5)\n",
    "alpha = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations work like you know from linear algebra: we can multiply any $n \\times m$ matrix with an $m$-dimendional vector, giving us a vector in $n$ dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.59698243,  0.65230239])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.dot(v)  # 2x5 matrix times 5-dim vector gives a 2-dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02554489,  0.03384006,  0.26629625,  0.25660951,  0.0146917 ],\n",
       "       [ 0.14710188,  0.09327531,  0.20719716,  0.05819591,  0.14653212]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M * v  # Don't confuse the above with the element-wise multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product is the most fundamental operations on vectors.  `x.dot(y)` compute the sum of the element-wise product of the two arrays.  If `x` and  `y` are equal-length arrays then the dot product is a scalar value.\n",
    "\n",
    "The `.dot` operator also defines matrix multiplication. If $x$ and $y$ are matrices then `x.dot(y)` is the product of the two matrices.  If two matrices are to be multiplied, the number of columns in the first matrix *must* match the number of rows in the second.  For the above to work, if `x` is an m x n matrix, then `y` must have n rows.  Then, the multiplication operation is just the dot product of all rows in $x$ with all columns in $y$.  Any cell $(i, j)$ in the product is `x_i.dot(y_j)` where $x_i$ is row $i$ and $y_j$ is column $j$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transposed matrix $M^T$ of $M$, which swaps rows with columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13298838,  0.7658221 ],\n",
       "       [ 0.20470843,  0.5642496 ],\n",
       "       [ 0.43728473,  0.34023819],\n",
       "       [ 0.59251793,  0.13437586],\n",
       "       [ 0.02563998,  0.25572802]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.T  # transpose 2x5 matrix to 5x2 one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.59698243,  0.65230239])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.dot(M.T)  # 5-dim vector times 5x2 matrix gives 2-dim vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar multiplication is straight-forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.32988379,  2.04708427,  4.37284733,  5.92517934,  0.25639977],\n",
       "       [ 7.65822096,  5.64249604,  3.4023819 ,  1.34375855,  2.55728017]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha * M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.92083616,  1.65308599,  6.08976794,  4.33083118,  5.72999879])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha * v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also matrices can be multiplied with each other..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77716772,  0.79474174,  0.57896433],\n",
       "       [ 1.38034767,  1.32252039,  1.22523139]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = np.random.random((5, 3))\n",
    "M.dot(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or with themselves (if $n = m$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17249202,  0.40365045,  0.53284669,  0.17779053,  0.32519868],\n",
       "       [ 0.28439827,  0.90610937,  0.18140915,  0.69444175,  0.61413287],\n",
       "       [ 0.0661374 ,  0.9773175 ,  0.01620026,  0.09241967,  0.51670086],\n",
       "       [ 0.90356179,  0.21492623,  0.46544369,  0.86079233,  0.28981792],\n",
       "       [ 0.19532   ,  0.43288774,  0.13355917,  0.63150408,  0.51643255]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.random((5,5))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40395461,  1.1351247 ,  0.29995469,  0.7186297 ,  0.79878159],\n",
       "       [ 1.06617376,  1.52823036,  0.72410269,  1.68216682,  1.26111163],\n",
       "       [ 0.47485591,  1.17162262,  0.32482417,  1.09779875,  0.92370731],\n",
       "       [ 1.08215138,  1.32482153,  0.967348  ,  1.27689926,  1.06546996],\n",
       "       [ 0.83710948,  0.96089846,  0.547673  ,  1.21740799,  0.84810231]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.dot(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40395461,  1.1351247 ,  0.29995469,  0.7186297 ,  0.79878159],\n",
       "       [ 1.06617376,  1.52823036,  0.72410269,  1.68216682,  1.26111163],\n",
       "       [ 0.47485591,  1.17162262,  0.32482417,  1.09779875,  0.92370731],\n",
       "       [ 1.08215138,  1.32482153,  0.967348  ,  1.27689926,  1.06546996],\n",
       "       [ 0.83710948,  0.96089846,  0.547673  ,  1.21740799,  0.84810231]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_power(A, 2)  # A squared, which is the same as A times A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.96218851,  4.26430867,  2.17318357,  4.41911357,  3.47438766],\n",
       "       [ 5.279937  ,  7.83447434,  3.97952308,  7.81508648,  6.30961789],\n",
       "       [ 3.55644678,  5.05207763,  2.66416406,  5.19500888,  4.10996541],\n",
       "       [ 4.58269421,  7.10184812,  3.4168563 ,  6.99577371,  5.69282218],\n",
       "       [ 3.65007893,  5.48815243,  2.76692142,  5.40619184,  4.40274657]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_power(A, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special matrix is the _identity matrix **1**_, which doesn't do much: _**1**A = A**1** = A_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.identity(5)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17249202,  0.40365045,  0.53284669,  0.17779053,  0.32519868],\n",
       "       [ 0.28439827,  0.90610937,  0.18140915,  0.69444175,  0.61413287],\n",
       "       [ 0.0661374 ,  0.9773175 ,  0.01620026,  0.09241967,  0.51670086],\n",
       "       [ 0.90356179,  0.21492623,  0.46544369,  0.86079233,  0.28981792],\n",
       "       [ 0.19532   ,  0.43288774,  0.13355917,  0.63150408,  0.51643255]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.dot(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17249202,  0.40365045,  0.53284669,  0.17779053,  0.32519868],\n",
       "       [ 0.28439827,  0.90610937,  0.18140915,  0.69444175,  0.61413287],\n",
       "       [ 0.0661374 ,  0.9773175 ,  0.01620026,  0.09241967,  0.51670086],\n",
       "       [ 0.90356179,  0.21492623,  0.46544369,  0.86079233,  0.28981792],\n",
       "       [ 0.19532   ,  0.43288774,  0.13355917,  0.63150408,  0.51643255]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.dot(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_power(I, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a matrix $A$ could have an inverse $A^{-1}$, such that $AA^{-1} = \\textbf{1} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., -0.,  0.],\n",
       "       [-0.,  1.,  0.,  0.,  0.],\n",
       "       [-0.,  0.,  1., -0.,  0.],\n",
       "       [ 0.,  0., -0.,  1., -0.],\n",
       "       [ 0., -0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "A.dot(A_inv).round(4)  # you might see weird \"negative zeroes\" in the matrix due to rouding errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the inverse $A^{-1}$ is literally $A$ to the power -1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(A_inv, np.linalg.matrix_power(A, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _rank_ of a matrix is its number of linearly-independent vectors. Its a fundamental result in linear algebra that the _column rank_ equals the _row rank_ of a matrix, so we safely speak of its _rank_ in general. Hence, it follows that rank $A$ = rank $A^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [6, 9, 12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    }
   ],
   "source": [
    "print np.linalg.matrix_rank(A), np.linalg.matrix_rank(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the third row is twice the first plus the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  9 12]\n",
      "[ 6  9 12]\n"
     ]
    }
   ],
   "source": [
    "print 2 * A[0] + A[1] \n",
    "print A[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But also, the third column is negative the first plus twice the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  6 12]\n",
      "[ 3  6 12]\n"
     ]
    }
   ],
   "source": [
    "print -A[:, 0] + 2 * A[:, 1]\n",
    "print A[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We say a matrix has _full rank_ if its rank equals the number of rows or columns, whichever is smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since matrices can be multiplied with vectors, we often regard them as linear transformations, or mappings, from one vector space to another:\n",
    "\n",
    "$$M: v \\mapsto Mv$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank is also the dimension of the image of the linear transformation that is given by multiplication by _M_. More generally, if a linear operator on a vector space (possibly infinite-dimensional) has finite-dimensional image (e.g., a finite-rank operator), then the rank of the operator is defined as the dimension of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a special case, when $n = m$, then rank $A = n$ if and only if its inverse $A^{-1}$ exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.random.random((20, 20))\n",
    "print np.linalg.matrix_rank(M)\n",
    "M_inv = np.linalg.inv(M)\n",
    "np.isclose(np.identity(20), M_inv.dot(M)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _norm_ of a vector is its distance to the Origin, or the length of its arrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1601186067634819"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.random.random(5)\n",
    "np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is computed by using Pythagoras (for any dimension): $a^2 + b^2 = c^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16011860676\n",
      "1.16011860676\n"
     ]
    }
   ],
   "source": [
    "print sum([elt ** 2 for elt in v]) ** (1/2.)  # in python style\n",
    "print np.sqrt(np.square(v).sum())  # numpy style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above norm using Pythogoras is called the Euclidean norm, or the L2-norm. \n",
    "- Another commonly used norm is the Manhattan distance, or the L1-norm: $||v|| = \\sum_i |v_i|$\n",
    "- It's called Manhattan distance, because you can only walk on a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9906856683365495"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(v, ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99068566834\n",
      "1.99068566834\n"
     ]
    }
   ],
   "source": [
    "print sum([abs(elt) for elt in v])  # in python style\n",
    "print np.abs(v).sum()  # numpy style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7856167815727257"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(v, ord=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/3e/Dot_Product.svg\"  style=\"height: 170px;\"/ align=right>\n",
    "- The _dot product_ or _inner product_ of two vectors $v$ and $w$ of the same dimension is defined as $<v, w> = \\sum_i v_i w_i$.\n",
    "- Note that the _dot product_ is a single value, or a scalar, and not a vector.\n",
    "- Geometrically, it's the length of the projection of the one vector onto the other (see picture).\n",
    "- That implies that $<v, w> = ||v||  ||w|| $ cos $\\theta$.\n",
    "- In an Euclidean space, we have $ ||v||^2 = <v, v>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1105542853696984"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.random(v.shape[0])\n",
    "v.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.34587518176\n",
      "1.34587518176\n"
     ]
    }
   ],
   "source": [
    "print np.linalg.norm(v) ** 2\n",
    "print v.dot(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The angle $\\theta$ can be computed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9258868904299643"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.arccos(v.dot(w) / (np.linalg.norm(v) * np.linalg.norm(w)))\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, two vectors are _orthogonal_ ($90^o$ angle) if their dot product is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (*) Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an arbitrary matrix _M_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72152139,  0.96889166],\n",
       "       [ 0.18037866,  0.89068293]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.random.random((2,2))\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know we can multiply this matrix with any 2-dimensional vector, which whill give us another 2-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.random.random(2)\n",
    "b = M.dot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw both vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def draw(a, lim=1.5):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    colors = list('kyrgb')\n",
    "    if type(a) != list:\n",
    "        a = [a]\n",
    "    for a in a:\n",
    "        c = colors.pop()\n",
    "        plt.arrow(0, 0, a[0], a[1], head_width=0.2, fc=c, ec=c)\n",
    "    plt.xlim(-lim, lim), plt.ylim(-lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANcAAADICAYAAAB7/XT7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAlG4RAJRuEQC+X8jL+MwarvCbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1069278d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw([a, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this matrix _M_, we now try to find a vector _v_, along with a scalar $\\lambda$, such that:\n",
    "- $M \\times v = \\lambda v$\n",
    "\n",
    "In fact, if we accept complex numbers, we know that each $n \\times n$-matrix has\n",
    "- $n$ such vectors, called _eigenvectors_, along with their\n",
    "- respective scalars, called _eigenvalues_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.37957984  1.23262448]\n",
      "[[-0.94299651 -0.88448135]\n",
      " [ 0.33280262 -0.46657554]]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(M)\n",
    "print eigenvalues\n",
    "print eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35794246  0.12632517] and [-0.35794246  0.12632517] : True\n",
      "[-1.09023337 -0.57511243] and [-1.09023337 -0.57511243] : True\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(len(eigenvalues)):\n",
    "    v = eigenvectors[:,i]  # columns are eigenvectors\n",
    "    print M.dot(v), \"and\", eigenvalues[i] * v, \":\", np.isclose(M.dot(v), eigenvalues[i] * v).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANcAAADICAYAAAB7/XT7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXCKBKFwigShcIoEoXCKBKFwigfw/WbsqfDJxI4kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1085e0210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw([eigenvectors[:,0], eigenvectors[:,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw the images $Mv = \\lambda v$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANcAAADICAYAAAB7/XT7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE7RJREFUeJzt3X2UVXW9x/H3d2bOPAoBMvKsk8qDQ6VAkuAlZpUoklLc\n8hI9ENA19fbgXRe9qbWCWl0tzVWLa6ariy4qC8x7I1I0HgIkSxJmmEAZYQxEYBxFHmWe53zvH3s7\nDPN45uzzO4/f11pnzdln/87+/X4Dn9n7/PY+vy2qijEm9rIS3QBj0pWFyxhHLFzGOGLhMsYRC5cx\njli4jHEkcLhE5DERqRWRXd2sLxORkyJS4T++HbROY1JBTgy28Tjw38AveiizRVVnx6AuY1JG4D2X\nqm4FjvdSTILWY0yqicdnLgWmikiliKwVkdI41GlMwsXisLA35cAoVa0TkeuB1cCYjoVExK7DMklL\nVft89OV8z6Wqp1W1zn/+LBASkUHdlI3bY8mSJWlbXzr3LRH1Rct5uERkiIiI/3wyIKp6zHW9xiRa\n4MNCEfkNMB0YLCJvAEuAEICqPgp8BrhNRFqAOuCzQes0JhUEDpeqzutl/U+BnwatJ9bKysrStr50\n7lsi6ouWBDmmjCUR0WRpizHtiQiajAMaxmQqC5cxjli4jHHEwmWMIxYuYxyxcBnjiIXLGEcsXMY4\nYuEyxhELlzGOWLiMccTCZYwjFi5jHLFwGeOIhcsYRyxcxjhi4TLGEQuXMY44nyveL7NMRPb5E4NO\nCFqnMakgFnuux4GZ3a0UkVnApao6GvgK8LMY1GlM0ovHXPGzgRV+2W3AABEZErReY5JdPD5zjQDe\naLd8CBgZh3qNSah4zBUPne9y0uUcakuXLm17XlZWljLz05n0snnzZjZv3hx4OzGZt1BESoA/qOoH\nu1j3CLBZVVf6y1XAdFWt7VDO5i00SSmZ5y1cA8wHEJGrgBMdg2VMOnI+V7yqrhWRWSJSDZwBFgat\n05hUYNNZG9OLZD4sNCYjWbiMccTCZYwjFi5jHLFwGeOIhcsYRyxcxjhi4TLGEQuXMY5YuIxxxMJl\njCMWLmMcsXAZ44iFyxhHLFzGOGLhMsYRC5cxjli4jHHEwmWMI7GYK36miFT5c8F/s4v1ZSJyUkQq\n/Me3g9ZpTCoINPuTiGQDDwHXAIeBl0Rkjaru6VB0i6rODlKXMakm6J5rMlCtqgdUtRlYCXyyi3J9\nnjnHmFQXNFxdzQM/okMZBab6tw9aKyKlAes0JiUEnRQ0kokGy4FRqlonItcDq4ExXRW0ueJNMkiK\nueL96amXqupMf/luIKyqP+zhPfuBSap6rMPrNimoSUqJmhR0OzBaREpEJBeYizc3fPuGDRER8Z9P\nxgv0sc6bMia9BDosVNUWEfka8EcgG1iuqntE5BZ//aPAZ4DbRKQFqAM+G7DNbWpr4Sc/gaYmyM09\n+8jJgVCo6589rSsthfPPj1XrTKZL+bni//pXuOEGOH4cVEEEsrLOPt5bFjn34dXp/VSF06fh4EEY\nabflMx1Ee1iY8uECeOstuPFG2L0b6uqiq3/CBCgvj+69Jr1l9I0YLrgAXngBvvIVKCzs+/uLiuDW\nW2PfLpPZ0mLP1d7vfgdf/KK3B4t0c3l5cOQIDBoUuHqThjJ6z9XenDlQUQElJZCfH9l7pk61YJnY\nS7twAYweDbt2waxZkR0mbtoEkybBvn3u22YyR1qGC7zPUU89BffdBwUF3ZfLzYX5873BjDFjvBHE\nOXPg7bfj11aTntI2XOAF5RvfgI0bvcO+UKhzmRtvhBUrvM9nhw7Bxz8Oq1d7gyQicPvtUF8f/7ab\n1JfW4XrPlCmwZ4833N7+MLFfP7j55rPLI0bAhg1e0CorvcPLZcu894jAgw9Ca2v8229SU9qNFvak\npQXuvBMefdTbG/XrB8eOeVdn9GTdOpg9Gxobz762ahXcdNPZE9EmfdloYQRycuDHP4YnnvBGEufN\n6z1YANdeCw0NEA7D8uXea3Pneld+jBpcz182NXorjWkno/Zc7e3bB83N3vWE0WhuhnvvhfVL/8xT\nfIah1KIIZGchWVmQnX3uIyfn3J+h0Nmf713geOml8Otfx7ajJrCMvvwp0U7vreGdqTdQ/M4eiohy\n9EMEvvxl+PnPY9s4E5gdFiZQvzHDKKl5kaKvLiKcH8X1V+CdO1i0KLYNMwlle65YW7XKC0l9feTX\nXwEUF3vfobERkqRje65kMXcu7NgBo0Z5Fy1GIhSCBQssWGnGwuXCuHHw8sswY0Zk1181N7Mve5z7\ndpm4ssNCl1S9M8/f+U7El3lUFUwg//erKJkx2nHjTKTssDAZicAdd3hnoQcO7PqkWn4+3Hsvpw6d\nYuvoRYyrr6DkWu8ix23DPsXRPXaRY6qyPVe81NR48xFUVZ37dem8PO+k26hRbS8deekwNdctYNLx\nDW2vbbn8G0z+0w8oGNTDVcjGiYTtuXqbK94vs8xfXykiE4LWmZKGDYMXX4SFC8/9HHbZZecEC2D4\nlSOYdGw9qLL3t5XsD41heuUyCs73LnLcfOODtDbZRY5JT1WjfuDN+FQNlAAhYCdwWYcys4C1/vOP\nAC92sy3NGCtXqhYVqYZCqo88EvHbtt/7R60jX9X7NKcK+sK/r9Jwa9hhY43/f7Pv+YjmTXo2EFOA\n59ot3wXc1aHMI8DcdstVwJAutuXut5OM9uxRHT9e9ejRPr813BrW5xcsPydkR2WwVj78ZwcNNdGG\nKx5zxXdVxiYwGzcOdu6MaqJEyRKmPb4IVGk+08TmsqWcr0f50L/9Ew1DhWe+OpZwi11InGjxmCse\nOt/lpMv3Zdxc8ZFckt+LUGGIsk1LqD35ObZtG0v/XCW3pppWaSKLCCcRMedImbniReQRYLOqrvSX\nq4DpqlrbYVsapC2Z6nTDUX6/+UJG5nvn0U6/705unHB/gluVXqIdLQz6p7NtrnjgCN5c8fM6lFkD\nfA1Y6YfxRMdgmb5rbm3gF+sv4pL8txiZDzW5n2Xe1N8kulmmHedzxavqWhGZJSLVwBlgYeBWZ7Bw\nOMzyjR9kdOgVLsmH/Xo1X5r+PFlZdj1AsrGTyCkiHA7zy63XcZF6J5arGy9h4YwqsrOCf24zPbMv\nS6ax325bRHH94wD8o34gn7vmIPmh8xLcqsxh4UpDz/19KfnHvgvAmw25zPzofgYUDk9wqzKPhSuN\n/KV6OU2H/hWA+lb40MRdjBj4gQS3KnMlarTQxNDLh5/l7X2z2paHjd3I2GEfS2CLTBAWriRw8J1y\n9lZOIscf8Cu88JdMvvgLiW2UCczClUDH3j3IxhcuoTivhZwsaC6+lxnj7050s0yM2GeuBKhvOsWq\njSMpKTgNwLGiW/nnK3+W4FaZ7tiARgpoaW3i8fWjGZ1/EIA3sj/BF6c9neBWmd5YuJJYOBzm8U1X\ncUn2SwC81nIFCz+2w66qSBEWriT1qz/PYWTLagCqG0ew4Jp/kJOdm+BWmb6wcCWZ1TtuZ8DpZQAc\nbCji02UHKcq3e8OmIgtXktj4yo/IfutOAN5pyuajU/ZR3O/9CW6VCcLClWDb96/k3dfPftum5AN/\no2TwlQlskYkVu0IjQfa++TxHqqa3LQ+65Pd8aNTsBLbIJAsLV5RqTuxhx/ZSzvN/g9nDH2bamNsS\n2yiTVDJ+LFhVWV21OuLyJ+tr+fVz+by60wtW3cB7KCtTC5bpJKPDpaosXreYOavmUFFT0WPZxuY6\nlj83mIptQxme30ht3hcoK1NmXf5fcWqtSTUZPaCxZNMSfvTXH1HXXMe0C6fx/MLnO5VpDbfw2Ibx\njM7dC8ABpjP/o3+yE8AZxEYL++iBFx5g6Zal1DV787YXhgp57vPPMe2iaYB3VcWK5z/G+9kCQHXT\nWBZes9u+Vp+B4h4uERkErAIuAg4A/6KqJ7oodwA4BbQCzao6uZvtxS1cD//tYe5Yfwf1Lefe1ufy\nIZdTcUsFT744nyGNvwLgHw2D+fzHXycvFOXtWE3KS0S47geOqur9/g0YBqrqXV2U2w9MUtVjvWwv\nLuFasXMFtz1zW6dgAVx9vvD9D3htONKQxw3TX6d/wRDnbTLJLRHhapvcU0SG4k382en2iH64Pqyq\n7/SyvZiFq6HhdcLhJgoLz72B3JMvP8mC1Qs6BWt8f3jIv/fK6WaY+OHdjBg4PiZtMakvEbcQGtJu\ncs9aoLs/8QpsEJHtInJzgPoi0thYQ3n5VKqrbz/n9adffbpTsC4shE3TzwZr3jaY91IRWw5Vum6m\nyQA9fjoXkfXA0C5Wfav9gqqqiHS327laVWtEpBhYLyJVqrq1q4JB54pvanqb8vIpNDXVcuLEFk6d\n2k7//h9mw2sbmPvU3LZgDc6F3045+76bd0D1u+8tnWHxusXcVHoToexQn+o36SHhc8X7h4Vlqvqm\niAwDNnV1WNjhPUuAd1X1wS7WBTosbG4+QXn5R6iv3w80A9C//xTqBz/Adb+6jjPNZyjKhseuhAvy\nvPcsroTyTkMwUBQq4oEZD3DblXZi2CRuQOMdVf2hiNwFDOg4oCEihUC2qp4WkSJgHfBdVV3Xxfai\nDldLy2kqKq6mru5VVJvabTSfu3fBjmMN/OQKKO3vvfy9V2BTL7caHpg/kMP/cZiCkN0mNdMlaij+\nSeBC2g3Fi8hw4Oeq+gkRuRj4P/8tOcATqnpfN9uLKlytrXVUVEznzJldqDb2WPahavjfw51fz8vO\nIz8nn8bWRgTh4oEXM3HYRO6Zdg/jBve4MzYZICNPIofDjVRWzuDUqZdQbei23O6T8PWdkJ+TT152\nHg0tDWRnZXPpwEu5YtgVTBo2ifHF4yktLmXoeUMR6fPv0aSxjAtXONzMrl03cPLkVsLhzues2jvW\nFOLpunlMGj6Z0uJSSotLuaDoAguRiUhGhUu1ld27P83x4+t6DRZAVlYRY8Y8zNCh84M202SgRJzn\nSgjVMHv2zOf48fURBQsgHD7Da6/dSTjc1HthY2IkpcKlquzdeytHj64mHK7r03tbWk5w5Mgjjlpm\nTGcpc4m3qvLaa4uprX0iomBlZRUgkks4XE9WVh4FBZfS3Nzj5Y3GxFTKhOvAgaUcOfJop2BlZRUi\nEvJDVEBBwWj69ZvIeedNoKiolMLCUnJzByeo1SaTpUS4Dh68n9df/x5ZWfmIhMjOPq9diCb6IbqM\nUMjmBTTJI+nD9e67u2hqqmXs2P+hsLCUoqJScnLel+hmGdOrlByKNyaeMmYo3phUYeEyxhELlzGO\nWLiMccTCZYwjFi5jHLFwGeOIhcsYRyxcxjhi4TLGkajDJSI3icjLItIqIhN7KDdTRKpEZJ8/7bUx\nGSHInmsXMAfofN8dn4hkAw8BM4FSYJ6IXBagTmNSRtRXxatqFdDbJC+TgWpVPeCXXQl8EtgTbb3G\npArXn7lGAG+0Wz7kv2ZM2ot2rvh7VPUPEWy/T98hCTpXvDGxkPC54ts2ILIJWKyq5V2suwpYqqoz\n/eW7gbCq/rCLsvZ9LpOUEv19ru4q3g6MFpESEckF5gJrYlSnMUktyFD8HBF5A7gKeEZEnvVfHy4i\nzwCoagvwNeCPwCvAKlW1wQyTEexr/sb0ItGHhcaYDixcxjhi4TLGEQuXMY5YuIxxxMJljCMWLmMc\nsXAZ44iFyxhHLFzGOGLhMsYRC5cxjli4jHHEwmWMIxYuYxyxcBnjiIXLGEcsXMY4YuEyxpF4zBV/\nQET+LiIVIvK3aOuLtVjMS5es9aVz3xJRX7SczhXvU6BMVSeo6uQA9cVUOv+HSOe+JaK+aLmeK/49\nfZ45x5hUF4/PXApsEJHtInJzHOozJin0OG9hJHPF9zSdtb9+mKrWiEgxsB74uqpu7aKcTVpoklY0\n8xb2eFioqjOib07bNmr8n2+LyO/wbivUKVzRNN6YZOZ0rngRKRSRfv7zIuBavIEQY9Ke07ni8Q4p\nt4rITmAb8LSqrgvaaGNSQdLMFW9MuknYFRrxPAkd75uji8ggEVkvIntFZJ2IDOimXKC+RdJeEVnm\nr68UkQl9raMv9YlImYic9PtTISLfDlDXYyJSKyLdfoyIcd96rC+qvqlqQh7AOGAMsAmY2EO5/cAg\n13UB2UA1UAKEgJ3AZVHWdz/wn/7zbwI/iHXfImkvMAtY6z//CPBigN9hJPWVAWti9P9jGjAB2NXN\n+pj1LcL6+ty3hO25VLVKVfdGWDzQSGKEdbXdHF1Vm4H3bo4ejdnACv/5CuBTPZSNtm+RtLetHaq6\nDRggIkMc1gcxumBAvdM1x3soEsu+RVIf9LFvqXDhbrxOQsfy5uhDVLXWf14LdPePHqRvkbS3qzIj\n+1hPX+pTYKp/mLZWREqjrCva9kTbt0j0uW9RX/4UiRjcsBzgam13ElpEqrTrk9BxvTl6D/V965yN\nqmoPJ8gj6ls3Im1vx7+20Y5gRfK+cmCUqtaJyPXAarzDcVdi1bdI9LlvTsOl8T0JHbSuw8Codsuj\n8P4adteubuvzPxgPVdU3RWQY8FY324iobwHa27HMSP+1aPRan6qebvf8WRF5WEQGqeqxKOvsS3uC\n9K1X0fQtWQ4L43kSOh43R18DfMl//iW8v3LnNiJ43yJp7xpgvl/HVcCJdoerfdVrfSIyRPwruUVk\nMt6pHhfBgtj2rVdR9S0WIztRjs7MwTtmrgfeBJ71Xx8OPOM/vxhvVGonsBu421Vd/vL1wKt4o2JR\n1eVvZxCwAdgLrAMGuOhbV+0FbgFuaVfmIX99JT2MysaiPuCrfl92An8BrgpQ12+AI0CT/2+3yHHf\neqwvmr7ZSWRjHEmWw0Jj0o6FyxhHLFzGOGLhMsYRC5cxjli4jHHEwmWMI/8PXwZedQ00CIQAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1085bd550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw([eigenvectors[:,0], eigenvectors[:,1],\n",
    "      M.dot(eigenvectors[:,0]), M.dot(eigenvectors[:,1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.37957984  1.23262448]\n"
     ]
    }
   ],
   "source": [
    "print eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the following matrix $M$, vector $v$ and scalar $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "v = np.array([2,4,6])\n",
    "alpha = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the mean of each row of $M$, and the mean of each column of $M$, and the mean of all of $M$\n",
    "- What is the standard deviation of $v$\n",
    "- What is $\\alpha M v$?\n",
    "- Can we compute $v M$? And what about $v  M^T$?\n",
    "- (*) What are the eigenvalues of $M$, and what are the corresponding eigenvectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
