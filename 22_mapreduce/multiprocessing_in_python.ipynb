{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Parallel Computing\n",
    "\n",
    "##multiprocessing\n",
    "\n",
    "Python has a neat `multiprocessing` package that will allow you to run your tasks using multiple cores in parallel.\n",
    "\n",
    "Let's use five cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_nodes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25, 36]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x * x\n",
    "\n",
    "p = Pool(n_nodes)  # specify the number of cores for parallel computing\n",
    "print p.map(f, [1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##MapReduce\n",
    "Although your tasks run locally, this is a nice simulation of MapReduce, since you'll be working with distributed systems as well.\n",
    "\n",
    "At first, we need to distribute our big dataset into several clusters. In real life, your big dataset usually lives across multiple nodes already.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distribute_data(data, n_nodes):\n",
    "    return [data[i::n_nodes] for i in xrange(n_nodes)]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the MapReduce framework, an operation consists of two steps:\n",
    "1. The **map** step performs the task locally on each node\n",
    "1. The **reduce** step aggregates all local results into the final result.\n",
    "\n",
    "For example, suppose we have a list of errors, and we would like to compute the mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 1e5  # some big number\n",
    "errors = np.random.randn(N)  # our list of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With python or numpy, we would compute the MSE as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00266565643\n",
      "1.00266565643\n"
     ]
    }
   ],
   "source": [
    "print sum([error ** 2 for error in errors]) / float(len(errors))  # python way (slow)\n",
    "print np.square(errors).mean()  # numpy way  (fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using distributed systems, we would define the map and reduce functions as follows. \n",
    "\n",
    "We intentionally write the code to be suboptimal, so it's rather slow and you'll see the effects of the parallellization more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_map(data):\n",
    "    \"\"\"Perform your function locally in one node\"\"\"\n",
    "    return sum([x ** 2 for x in data]), len(data)  # return result and the count\n",
    "    \n",
    "def f_reduce(data):\n",
    "    \"\"\"Reduce all the local results back to final answer\"\"\"\n",
    "    sums, counts = np.array(data).T\n",
    "    return sums.sum() / counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we indeed get the same if we would pipe these functions directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00266565643\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "mse = f_reduce([f_map(errors)])\n",
    "print mse\n",
    "print np.isclose(mse, np.square(errors).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use distributed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0026656564318008"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_reduce([f_map(data) for data in distribute_data(errors, n_nodes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's use the actual cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0026656564318008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Pool(n_nodes)\n",
    "f_reduce(p.map(f_map, distribute_data(errors, n_nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "Let's compare the duration of serial computing with parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1e6  # one million samples\n",
    "errors = np.random.randn(N)\n",
    "distributed_data = distribute_data(errors, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 315 ms per loop\n",
      "10 loops, best of 3: 95.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit f_reduce([f_map(data) for data in distributed_data])  # serialized mapreduce\n",
    "%timeit f_reduce(p.map(f_map, distributed_data))  # parallel mapreduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using several cores in parallel is indeed a multiple faster than serial computing. \n",
    "\n",
    "It takes time to spin up machines in a network and to distribute your data amongst them. Hence, the parallel computing pays off when your data is very big and your operation is rather slow.\n",
    "\n",
    "Let's try a larger number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 1e7  # ten million samples\n",
    "errors = np.random.randn(N)\n",
    "distributed_data = distribute_data(errors, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 3.14 s per loop\n",
      "1 loops, best of 3: 938 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit f_reduce([f_map(data) for data in distributed_data])  # serialized mapreduce\n",
    "%timeit f_reduce(p.map(f_map, distributed_data))  # parallel mapreduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More or less same factor.\n",
    "\n",
    "### NumPy\n",
    "\n",
    "Note, however, that for these kinds of operations, just a simple `numpy` operation beats all other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 29.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit np.square(errors).mean()  # numpy way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SciPy.org](http://wiki.scipy.org/ParallelProgramming) writes this about that:\n",
    "    \n",
    "One of the great strengths of numpy is that you can express array operations very cleanly. For example to compute the product of the matrix A and the matrix B, you just do:\n",
    "\n",
    "     C = numpy.dot(A,B)\n",
    "\n",
    "Not only is this simple and clear to read and write, since numpy knows you want to do a matrix dot product it can use an optimized implementation obtained as part of \"BLAS\" (the Basic Linear Algebra Subroutines). This will normally be a library carefully tuned to run as fast as possible on your hardware by taking advantage of cache memory and assembler implementation. But many architectures now have a BLAS that also takes advantage of a multicore machine. If your numpy/scipy is compiled using one of these, then `dot()` will be computed in parallel (if this is faster) without you doing anything. Similarly for other matrix operations, like inversion, singular value decomposition, determinant, and so on. For example, the open source library ATLAS allows compile time selection of the level of parallelism (number of threads). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "## Exercise\n",
    "\n",
    "Using `multiprocessing.Pool`, write a mapreduce job for a common task that is easy to parallize. You could think of averaging numbers, counting words or maybe even a `mergesort` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
