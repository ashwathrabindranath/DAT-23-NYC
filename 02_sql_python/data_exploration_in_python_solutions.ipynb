{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration in Python (without pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use python to parse some datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Reviews Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we've worked mainly with CSV data that has been easy to import. However, often its not the modeling part that is difficult (once we understand the models) but getting data into a format that we can use for modeling.\n",
    "\n",
    "Today we'll look at 2 datasets from Amazon. The first is a collection of movie reviews (the original set of 7 million reviews is also available) and the second is meta data on products including which customers reviewed it. However, neither is in a ready-to-use format so we must work on that first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use limited version of this data, which is stored in our repo under `/data/amazon/small-movies.txt`\n",
    "- The full data set is available\n",
    "<a href=\"http://snap.stanford.edu/data/web-Movies.html\" target=\"_blank\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace the following path to your own local path\n",
    "path_to_repo = \"/Users/ruben/repo/personal/ga/DAT-23-NYC/\"\n",
    "path_to_data = path_to_repo + \"data/amazon/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset into a list of separate lines in python\n",
    "with open(path_to_data + 'small-movies.txt') as f:\n",
    "    lines = [line for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tab-separated file from the file above the contains the following columns: productId, userId, review text, helpfulness score (as a numeric value) and review score (as a numeric value).\n",
    "Note: What are the issues with helpfulness? How can you resolve them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "record = {}\n",
    "\n",
    "for line in lines:\n",
    "    if line.startswith('product/productId: '):\n",
    "        if record:\n",
    "            reviews.append(record)\n",
    "        record = {'productId': line[len('product/productId: '):].strip()}\n",
    "    elif line.startswith('review/userId: '):\n",
    "        record['userId'] = line[len('review/userId: '):].strip()\n",
    "    elif line.startswith('review/helpfulness: '):\n",
    "        n, d = line[len('review/helpfulness: '):].strip().split('/')\n",
    "        try:\n",
    "            record['helpfulness'] = float(n) / float(d)\n",
    "        except:\n",
    "            record['helpfulness'] = None\n",
    "    elif line.startswith('review/score: '):\n",
    "        record['score'] = float(line[len('review/score: '):].strip())\n",
    "    elif line.startswith('review/text: '):\n",
    "        record['text'] = line[len('review/text: '):].strip()\n",
    "\n",
    "if record:\n",
    "    reviews.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of rows to be written to file\n",
    "rows = []\n",
    "\n",
    "columns = ['productId', 'userId', 'score', 'helpfulness', 'text']\n",
    "rows.append(\"\\t\".join(columns))  # first write header row\n",
    "for review in reviews:\n",
    "    rows.append(\"\\t\".join([str(review[col]) for col in columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['productId\\tuserId\\tscore\\thelpfulness\\ttext',\n",
       " 'B003AI2VGA\\tA141HP4LYPWMSR\\t3.0\\t1.0\\tSynopsis: On the daily trek from Juarez, Mexico to El Paso, Texas an ever increasing number of female workers are found raped and murdered in the surrounding desert. Investigative reporter Karina Danes (Minnie Driver) arrives from Los Angeles to pursue the story and angers both the local police and the factory owners who employee the undocumented aliens with her pointed questions and relentless quest for the truth.<br /><br />Her story goes nationwide when a young girl named Mariela (Ana Claudia Talancon) survives a vicious attack and walks out of the desert crediting the Blessed Virgin for her rescue. Her story is further enhanced when the \"Wounds of Christ\" (stigmata) appear in her palms. She also claims to have received a message of hope for the Virgin Mary and soon a fanatical movement forms around her to fight against the evil that holds such a stranglehold on the area.<br /><br />Critique: Possessing a lifelong fascination with such esoteric matters as Catholic mysticism, miracles and the mysterious appearance of the stigmata, I was immediately attracted to the \\'05 DVD release `Virgin of Juarez\\'. The film offers a rather unique storyline blending current socio-political concerns, the constant flow of Mexican migrant workers back and forth across the U.S./Mexican border and the traditional Catholic beliefs of the Hispanic population. I must say I was quite surprised by the unexpected route taken by the plot and the means and methods by which the heavenly message unfolds.<br /><br />`Virgin of Juarez\\' is not a film that you would care to watch over and over again, but it was interesting enough to merit at least one viewing. Minnie Driver delivers a solid performance and Ana Claudia Talancon is perfect as the fragile and innocent visionary Mariela. Also starring Esai Morales and Angus Macfadyen (Braveheart).']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write rows to disk\n",
    "output_file = path_to_data + 'small-movies-results.csv'\n",
    "with open(output_file, 'w') as f:\n",
    "    for row in rows:\n",
    "        f.write(row + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ensure that you have a properly formatted TSV and that you can parse it back in with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>userId</th>\n",
       "      <th>score</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> B003AI2VGA</td>\n",
       "      <td> A141HP4LYPWMSR</td>\n",
       "      <td> 3</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> Synopsis: On the daily trek from Juarez, Mexic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> B003AI2VGA</td>\n",
       "      <td> A328S9RN3U5M68</td>\n",
       "      <td> 3</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> THE VIRGIN OF JUAREZ is based on true events s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> B003AI2VGA</td>\n",
       "      <td> A1I7QGUDP043DG</td>\n",
       "      <td> 5</td>\n",
       "      <td> 0.8</td>\n",
       "      <td> The scenes in this film can be very disquietin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> B003AI2VGA</td>\n",
       "      <td> A1M5405JH9THP9</td>\n",
       "      <td> 3</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> THE VIRGIN OF JUAREZ (2006)&lt;br /&gt;directed by K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> B003AI2VGA</td>\n",
       "      <td>  ATXL536YX71TR</td>\n",
       "      <td> 3</td>\n",
       "      <td> 1.0</td>\n",
       "      <td> Informationally, this SHOWTIME original is ess...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    productId          userId  score helpfulness  \\\n",
       "0  B003AI2VGA  A141HP4LYPWMSR      3         1.0   \n",
       "1  B003AI2VGA  A328S9RN3U5M68      3         1.0   \n",
       "2  B003AI2VGA  A1I7QGUDP043DG      5         0.8   \n",
       "3  B003AI2VGA  A1M5405JH9THP9      3         1.0   \n",
       "4  B003AI2VGA   ATXL536YX71TR      3         1.0   \n",
       "\n",
       "                                                text  \n",
       "0  Synopsis: On the daily trek from Juarez, Mexic...  \n",
       "1  THE VIRGIN OF JUAREZ is based on true events s...  \n",
       "2  The scenes in this film can be very disquietin...  \n",
       "3  THE VIRGIN OF JUAREZ (2006)<br />directed by K...  \n",
       "4  Informationally, this SHOWTIME original is ess...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check if it indeed works\n",
    "import pandas as pd  # more on pandas later\n",
    "df = pd.read_csv(output_file, sep='\\t', header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1111"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows do we have?\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A limited version of this data is available here and the full data set is available here\n",
    "\n",
    "- We use limited version of this data, which is stored in our repo under `/data/amazon/small-amazon-meta.txt`\n",
    "- The full data set is available\n",
    "<a href=\"http://snap.stanford.edu/data/amazon-meta.html\" target=\"_blank\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task here is to parse this file into a collection of product ids (ASIN), title and list of customers (by id) who have reviewed the product.\n",
    "\n",
    "```\n",
    "productID, title, [customer1, customer2]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset into a list of separate lines in python\n",
    "with open(path_to_data + 'small-amazon-meta.txt') as f:\n",
    "    lines = [line for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = []\n",
    "metadata = {}\n",
    "\n",
    "line_no = 0\n",
    "while line_no < len(lines):\n",
    "    line = lines[line_no]\n",
    "    if line.startswith('ASIN:'):\n",
    "        if metadata:\n",
    "            products.append(metadata)\n",
    "        metadata = {'productID': line[5:].strip()}\n",
    "    elif line.startswith('  title:'):\n",
    "        metadata['title'] = line[len('  title:'):].strip()\n",
    "    elif line.startswith('  reviews:'):\n",
    "        number_of_customers = int(line[len('  reviews: total:'):].split()[0])\n",
    "        metadata['customers'] = []\n",
    "        for i in xrange(number_of_customers):\n",
    "            line_no += 1\n",
    "            line = lines[line_no]\n",
    "            pos = line.find('cutomer:')  # NOTE the typo!\n",
    "            if pos > -1:\n",
    "#                 print line\n",
    "                metadata['customers'].append(line[pos + len('cutomer:'):].split()[0])\n",
    "    line_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0771044445, , []\n",
      "0827229534, Patterns of Preaching: A Sermon Sampler, [A2JW67OY8U6HHK, A2VE83MZF98ITY]\n",
      "0738700797, Candlemas: Feast of Flames, [A11NCO6YTE4BTJ, A9CQ3PLRNIR83, A13SG9ACZ9O5IM, A1BDAI6VEYMAZA, A2P6KAWXJ16234, AMACWC3M7PQFR, A3GO7UV9XX14D8, A1GIL64QK68WKL, AEOBOF2ONQJWV, A3IGHTES8ME05L, A1CP26N8RHYVVO, ANEIANH0WAT9D]\n",
      "0486287785, World War II Allied Fighter Planes Trading Cards, [A3IDGASRQAW8B2]\n",
      "0842328327, Life Application Bible Commentary: 1 and 2 Timothy and Titus, [A2591BUPXCS705]\n"
     ]
    }
   ],
   "source": [
    "for product in products[:5]:  # just print first 5\n",
    "    print product['productID'] + ', ' + product.get('title', '') + ',',\n",
    "    print '[' + ', '.join([customer for customer in product.get('customers', [])]) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's write it to file, and try to load back. I am using | to \n",
    "with open(path_to_data + 'small-amazon-meta-results.csv', 'w') as f:\n",
    "    for product in products:\n",
    "        f.write(\"%s|%s|%s\\n\" % (product['productID'],\n",
    "                              product.get('title'), \n",
    "                              [customer for customer in product.get('customers', [])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0771044445</td>\n",
       "      <td>                                              None</td>\n",
       "      <td>                                                []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0827229534</td>\n",
       "      <td>           Patterns of Preaching: A Sermon Sampler</td>\n",
       "      <td>              ['A2JW67OY8U6HHK', 'A2VE83MZF98ITY']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0738700797</td>\n",
       "      <td>                        Candlemas: Feast of Flames</td>\n",
       "      <td> ['A11NCO6YTE4BTJ', 'A9CQ3PLRNIR83', 'A13SG9ACZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0486287785</td>\n",
       "      <td>  World War II Allied Fighter Planes Trading Cards</td>\n",
       "      <td>                                ['A3IDGASRQAW8B2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0842328327</td>\n",
       "      <td> Life Application Bible Commentary: 1 and 2 Tim...</td>\n",
       "      <td>                                ['A2591BUPXCS705']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1  \\\n",
       "0  0771044445                                               None   \n",
       "1  0827229534            Patterns of Preaching: A Sermon Sampler   \n",
       "2  0738700797                         Candlemas: Feast of Flames   \n",
       "3  0486287785   World War II Allied Fighter Planes Trading Cards   \n",
       "4  0842328327  Life Application Bible Commentary: 1 and 2 Tim...   \n",
       "\n",
       "                                                   2  \n",
       "0                                                 []  \n",
       "1               ['A2JW67OY8U6HHK', 'A2VE83MZF98ITY']  \n",
       "2  ['A11NCO6YTE4BTJ', 'A9CQ3PLRNIR83', 'A13SG9ACZ...  \n",
       "3                                 ['A3IDGASRQAW8B2']  \n",
       "4                                 ['A2591BUPXCS705']  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(path_to_data + 'small-amazon-meta-results.csv', header=None, sep='|').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 2 2 3 5 10 Error!\n",
      "at i = 50\n",
      "-10 -5 -4 -3 -2 -2 -2 -2 -2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"
     ]
    }
   ],
   "source": [
    "# NOTE: while debugging, you might want to use try/except\n",
    "for i in xrange(100):\n",
    "    try:\n",
    "        print 10/(50-i),\n",
    "    except:\n",
    "        print \"Error!\"\n",
    "        print \"at i =\", i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (**) If you'd like, create a review class that holds the customer id and star rating. Use this to output a product id, title and list of reviews.\n",
    "- (*) Create a product class that holds the id, title and collection of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Okay, this one is a little too much for the experts.\n",
    "## Contact me if you're interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lahman Baseball Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available here: \n",
    "<a href=\"http://seanlahman.com/files/database/lahman-csv_2014-02-14.zip\">Lahman Baseball Dataset</a>.\n",
    "\n",
    "- Without using Pandas, read in Salaries.csv and output average salary by playerID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "salaries = {}\n",
    "with open('/Users/ruben/Downloads/lahman-csv_2014-02-14/Salaries.csv') as f:\n",
    "    f.readline()  # read first line of headers: yearID,teamID,lgID,playerID,salary\n",
    "    for line in f:\n",
    "        yearID, teamID, lgID, playerID, salary = line.split(',')\n",
    "        if playerID not in salaries:\n",
    "            salaries[playerID] = []\n",
    "        salaries[playerID].append(int(salary.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_salaries = {player: sum(salaries[player]) / float(len(salaries[player])) \n",
    "                for player in salaries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# avg_salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (**) Without using Pandas, read in Salaries.csv and Master.csv and output salary by nameFirst and nameLast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'playerID'), (1, 'birthYear'), (2, 'birthMonth'), (3, 'birthDay'), (4, 'birthCountry'), (5, 'birthState'), (6, 'birthCity'), (7, 'deathYear'), (8, 'deathMonth'), (9, 'deathDay'), (10, 'deathCountry'), (11, 'deathState'), (12, 'deathCity'), (13, 'nameFirst'), (14, 'nameLast'), (15, 'nameGiven'), (16, 'weight'), (17, 'height'), (18, 'bats'), (19, 'throws'), (20, 'debut'), (21, 'finalGame'), (22, 'retroID'), (23, 'bbrefID')]\n"
     ]
    }
   ],
   "source": [
    "# Look up which columns we need in Master\n",
    "header = 'playerID,birthYear,birthMonth,birthDay,birthCountry,birthState,birthCity,deathYear,deathMonth,deathDay,deathCountry,deathState,deathCity,nameFirst,nameLast,nameGiven,weight,height,bats,throws,debut,finalGame,retroID,bbrefID'\n",
    "print list(enumerate(header.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_salaries_by_name = {}\n",
    "with open('/Users/ruben/Downloads/lahman-csv_2014-02-14/Master.csv') as f:\n",
    "    f.readline()  # read first line of headers: yearID,teamID,lgID,playerID,salary\n",
    "    for line in f:\n",
    "        cols = line.split(',')\n",
    "        playerID, nameFirst, nameLast = cols[0], cols[13], cols[14]\n",
    "        if playerID in salaries:\n",
    "            avg_salaries_by_name[nameFirst + ' ' + nameLast] = avg_salaries[playerID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# avg_salaries_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
